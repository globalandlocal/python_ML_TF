{"metadata":{"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8"},"kernelspec":{"name":"python","display_name":"Python (Pyodide)","language":"python"},"colab":{"provenance":[]},"accelerator":"TPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["! pip install kaggle\n","! mkdir ~/.kaggle\n","! cp ~/kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"PYiD6bS5gPHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! kaggle competitions download -c ml-intensive-yandex-autumn-2023"],"metadata":{"id":"K6TbdTaJ3q9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip /content/ml-intensive-yandex-autumn-2023.zip -d /root\n","! mkdir /root/model1\n","! mkdir /root/model2\n","! mkdir /root/data/slice_train_images"],"metadata":{"id":"X0vTpGD836VJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras import layers\n","from sklearn.metrics import f1_score\n","import os\n","\n","#URLы для картинок\n","train_url = '/root/data/train_images/'\n","train_mask_url = '/root/data/train_lung_masks/'\n","train_label_url = '/root/data/train_answers.csv'\n","test_url = '/root/data/test_images/'\n","slice_train_url = '/root/data/slice_train_images'\n","# URL куда я сохранял модель\n","save_model = '/root/model1/'\n","# загрузка имен картинок и их обрезание до чисел, понадобится при сохранении результатов предсказания модели в CSV\n","path = os.listdir('/root/data/test_images')\n","path = [int(i[4:-4]) for i in path]\n","'''\n","# для перевода картинок в массивы Numpy\n","image_list = os.listdir(train_url)\n","train_list = []\n","mask_list = []\n","for i in image_list:\n","    image = Image.open(train_url+'\\\\'+i)\n","    image = np.asarray(image)\n","    train_list.append(image)\n","    image = Image.open(train_mask_url+'\\\\'+i)\n","    image = np.asarray(image)\n","    mask_list.append(image)\n","print('download complete')\n","# перевод списка в массив Numpy\n","train_list = np.array(train_list)\n","# перевод маски в массив нулей и единиц для умножения\n","mask_list = np.array(mask_list)//255\n","# выделение легких по маскам\n","slice_list = train_list*mask_list\n","print('preprocess complete')\n","# сохранение обрезанных легких\n","for i in range(len(slice_list)):\n","    image = Image.fromarray(slice_list[i],mode='L')\n","    image.save(slice_train_url+'\\\\'+image_list[i])\n","print('Save complete')\n","#просмотр вырезанных легких\n","plt.figure(figsize=(15,8))\n","for i in range(5):\n","    plt.subplot(2,5,1+i)\n","    plt.imshow(train_list[i])\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.subplot(2,5,6+i)\n","    plt.imshow(slice_list[i])\n","    plt.xticks([])\n","    plt.yticks([])\n","plt.show()\n","'''\n","# блок с переменными\n","EPOCHS = 50\n","batch_size = 20\n","input_shape = (128, 128, 1)\n","# чтение меток\n","train_label = pd.read_csv(train_label_url)\n","# перевод id в строку для сопоставления сортировки с названиями картинок\n","train_label['id'] = train_label['id'].astype('string')\n","train_label = train_label.sort_values(by='id', ascending=True)\n","# переводим метки в список\n","train_label = list(train_label['target_feature']>0)\n","# загрузка и разделение на train и valid,\n","# color_mode - формат картинок в сером стиле(одно измерение)\n","# validation_split- разделение 27000 на 24к и 3к\n","# subset- для указания какой будет датасет (train, valid или both-оба)\n","# image_size - размер картинок при импорте,\n","# забыл сказать что при уменьшении размера они еще и памяти жрут в 2 раза меньше, что прям хорошо\n","train_set, valid_set = keras.utils.image_dataset_from_directory(train_url, labels=train_label, batch_size=batch_size,\n","                                                                shuffle=False, color_mode='grayscale',\n","                                                                validation_split=1 / 9, subset='both',\n","                                                                image_size=(128, 128))\n","# выделение меток из валидационного сета,\n","# пришлось выделять из датасета что бы не потерялось сопоставление картинок и меток\n","b = valid_set.map(lambda x,y:y)\n","b = np.array([i.numpy() for i in b])\n","b = b.reshape(3000)\n","# загрузка тестового датасета\n","test_set = keras.utils.image_dataset_from_directory(test_url, labels=None, image_size=(128, 128),\n","                                                    color_mode='grayscale',shuffle=False)\n","\n","'''\n","# визуализация датасетов\n","class_names = ['not_sick', 'not_covid', 'covid']\n","plt.figure(figsize=(15, 8))\n","for i in train_set.take(1):\n","    for j in range(20):\n","        plt.subplot(4, 5, 1 + j)\n","        plt.imshow(i[0][j].numpy() / 255)\n","        plt.title(int(i[1][j]))\n","        plt.xticks([])\n","        plt.yticks([])\n","plt.grid(False)\n","plt.savefig('set1.png')\n","'''\n","# аугментационная модель\n","aug = keras.Sequential([\n","    layers.RandomFlip(seed=42),\n","    layers.RandomContrast(factor=0.1, seed=42),\n","    layers.RandomBrightness(factor=0.1, value_range=(0, 255), seed=42),\n","    layers.RandomRotation(factor=0.1, seed=42)\n","])\n","# обработка датасета в отдельную переменную, что бы потом их можно было сложить в один датасет\n","train_set2 = train_set.map(lambda x, y: (aug(x), y))\n","\n","'''\n","# визуализация аугментированных картинок\n","plt.figure(figsize=(15, 8))\n","for i in train_set2.take(1):\n","    for j in range(20):\n","        plt.subplot(4, 5, 1 + j)\n","        plt.imshow(i[0][j].numpy() / 255)\n","        plt.title(int(i[1][j]))\n","        plt.xticks([])\n","        plt.yticks([])\n","plt.grid(False)\n","plt.savefig('set2.png')\n","'''\n","# объединение аугментации с обычным датасетом и удаление аугментационной переменной для экономии оперативки\n","train_set = train_set.concatenate(train_set2)\n","del train_set2\n","\n","# функция для создания моделей\n","def build_model(x=1):\n","    if x == 1:\n","        mod = tf.keras.Sequential([\n","            layers.Rescaling(1 / 255),\n","            layers.Input(input_shape),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Flatten(),\n","            layers.Dense(600, activation='relu'),\n","            layers.Dropout(0.5),\n","            layers.Dense(30, activation='relu'),\n","            layers.Dense(3, activation='softmax')\n","        ])\n","    elif x == 2:\n","        mod = tf.keras.Sequential([\n","            layers.Rescaling(1 / 255),\n","            layers.Input(input_shape),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2,2)),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.5),\n","            layers.AvgPool2D((2, 2)),\n","            layers.Flatten(),\n","            layers.Dense(30, activation='relu'),\n","            layers.Dense(30, activation='relu'),\n","            layers.Dense(3, activation='softmax')\n","        ])\n","    elif x == 3:\n","        mod = tf.keras.Sequential([\n","            layers.Rescaling(1 / 255),\n","            layers.Input(input_shape),\n","            layers.Conv2D(32, 3, activation='relu', padding='same', strides=1),\n","            layers.Dropout(0.4),\n","            layers.AvgPool2D((2,2)),\n","            layers.Flatten(),\n","            layers.Dense(300, activation='relu'),\n","            layers.Dropout(0.2),\n","            layers.Dense(200, activation='relu'),\n","            layers.Dropout(0.2),\n","            layers.Dense(100, activation='relu'),\n","            layers.Dropout(0.1),\n","            layers.Dense(3, activation='softmax')\n","        ])\n","    return mod\n","\n","\n","model = build_model(1)\n","# здесь думаю и так все понятно)\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n","              loss=keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=[\"accuracy\"]\n","              )\n","# callback - выполняет действие при каком то условии,\n","# в данном случае сохраняет модель после эпохи,\n","# если на этой эпохе получен лучший результат, чем ранее\n","callbacks = keras.callbacks.ModelCheckpoint(\n","    save_model,\n","    # monitor - то за чем следит модель, можно указать val_loss или train_accuracy\n","    monitor=\"val_accuracy\",\n","    verbose=1, # сообщает когда выполнен callback 0-не сообщать\n","    save_best_only=True, # сохранять лучшую модель\n","    save_weights_only=True, # сохранять только весы(можно целиком, но тогда модель будет переписана полностью,\n","    # и будет как в момент сохранения)\n","    mode=\"auto\", # ориентация для monitor, может быть max ,min , auto (например max val_loss-будет сохранять модель\n","    # при увеличении лосса\n","    save_freq=\"epoch\", # когда сохранять\n","    initial_value_threshold=None, # начальное значение для перезаписи(например если задать 0.9,\n","    # перепишет модель только если monitor будет выше/ниже этого значения)\n",")\n","# загрузка весов из модели, лучше закомментить в первый раз или если изменил параметры модели, иначе выдаст ошибку\n","#model.load_weights(save_model)\n","# запуск обучения\n","history = model.fit(train_set, epochs=EPOCHS, validation_data=valid_set, shuffle=True, callbacks=callbacks)\n","# эти строки для сравнения accurracy с f1-score,сами увидите что результаты почти не отличаются.\n","check = model.predict(valid_set)\n","check = tf.argmax(check, axis=1)\n","check = f1_score(check, b,average='micro')\n","print(check)\n","# собственно предсказание по тестовой выборке с текущей моделью\n","ans = model.predict(test_set)\n","ans = tf.argmax(ans, axis=1)\n","# перевод в pd.DataFrame  и сохранение\n","ans = pd.DataFrame(data=ans, columns=['target_feature'])\n","ans['id'] = path\n","ans = ans.sort_values('id')\n","ans.to_csv('ans1.csv', encoding='utf-8',index=False)\n","# теперь загружаем лучшую модель и повторяем предсказание на тестовой выборке\n","model.load_weights(save_model)\n","ans = model.predict(test_set)\n","ans = tf.argmax(ans, axis=1)\n","ans = pd.DataFrame(data=ans, columns=['target_feature'])\n","ans['id'] = path\n","ans = ans.sort_values('id')\n","ans.to_csv('ans2.csv', encoding='utf-8',index=False)\n","# просмотр графиков\n","plt.figure(figsize=(15, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('score')\n","plt.legend(loc='lower right')\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('score')\n","plt.legend(loc='lower right')"],"metadata":{"id":"AtTFUHOrGa2e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"466eaa24-8040-44d7-a150-74050c24d86d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 27000 files belonging to 2 classes.\n","Using 24000 files for training.\n","Using 3000 files for validation.\n","Found 6920 files belonging to 1 classes.\n","Epoch 1/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.4989 - accuracy: 0.7647\n","Epoch 1: val_accuracy improved from -inf to 0.83133, saving model to /root/model/\n","2400/2400 [==============================] - 110s 45ms/step - loss: 0.4990 - accuracy: 0.7647 - val_loss: 0.3972 - val_accuracy: 0.8313\n","Epoch 2/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8042\n","Epoch 2: val_accuracy improved from 0.83133 to 0.85767, saving model to /root/model/\n","2400/2400 [==============================] - 107s 45ms/step - loss: 0.4182 - accuracy: 0.8041 - val_loss: 0.3466 - val_accuracy: 0.8577\n","Epoch 3/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8166\n","Epoch 3: val_accuracy did not improve from 0.85767\n","2400/2400 [==============================] - 102s 43ms/step - loss: 0.3987 - accuracy: 0.8166 - val_loss: 0.3410 - val_accuracy: 0.8540\n","Epoch 4/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.8310\n","Epoch 4: val_accuracy improved from 0.85767 to 0.86200, saving model to /root/model/\n","2400/2400 [==============================] - 107s 45ms/step - loss: 0.3729 - accuracy: 0.8310 - val_loss: 0.3382 - val_accuracy: 0.8620\n","Epoch 5/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8419\n","Epoch 5: val_accuracy improved from 0.86200 to 0.86700, saving model to /root/model/\n","2400/2400 [==============================] - 112s 47ms/step - loss: 0.3549 - accuracy: 0.8419 - val_loss: 0.3202 - val_accuracy: 0.8670\n","Epoch 6/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8478\n","Epoch 6: val_accuracy improved from 0.86700 to 0.87467, saving model to /root/model/\n","2400/2400 [==============================] - 108s 45ms/step - loss: 0.3357 - accuracy: 0.8478 - val_loss: 0.3220 - val_accuracy: 0.8747\n","Epoch 7/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8572\n","Epoch 7: val_accuracy improved from 0.87467 to 0.87567, saving model to /root/model/\n","2400/2400 [==============================] - 110s 46ms/step - loss: 0.3155 - accuracy: 0.8572 - val_loss: 0.3148 - val_accuracy: 0.8757\n","Epoch 8/50\n","2398/2400 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8669\n","Epoch 8: val_accuracy did not improve from 0.87567\n","2400/2400 [==============================] - 99s 41ms/step - loss: 0.2976 - accuracy: 0.8669 - val_loss: 0.3068 - val_accuracy: 0.8733\n","Epoch 9/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.8715\n","Epoch 9: val_accuracy did not improve from 0.87567\n","2400/2400 [==============================] - 99s 41ms/step - loss: 0.2865 - accuracy: 0.8715 - val_loss: 0.3368 - val_accuracy: 0.8567\n","Epoch 10/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.8763\n","Epoch 10: val_accuracy improved from 0.87567 to 0.87800, saving model to /root/model/\n","2400/2400 [==============================] - 107s 44ms/step - loss: 0.2787 - accuracy: 0.8762 - val_loss: 0.3132 - val_accuracy: 0.8780\n","Epoch 11/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.2689 - accuracy: 0.8799\n","Epoch 11: val_accuracy did not improve from 0.87800\n","2400/2400 [==============================] - 99s 41ms/step - loss: 0.2691 - accuracy: 0.8799 - val_loss: 0.3161 - val_accuracy: 0.8723\n","Epoch 12/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.8827\n","Epoch 12: val_accuracy did not improve from 0.87800\n","2400/2400 [==============================] - 100s 42ms/step - loss: 0.2649 - accuracy: 0.8826 - val_loss: 0.3177 - val_accuracy: 0.8723\n","Epoch 13/50\n","2399/2400 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.8873\n","Epoch 13: val_accuracy did not improve from 0.87800\n","2400/2400 [==============================] - 100s 42ms/step - loss: 0.2586 - accuracy: 0.8872 - val_loss: 0.3167 - val_accuracy: 0.8647\n","Epoch 14/50\n","2400/2400 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.8880"]}]}]}